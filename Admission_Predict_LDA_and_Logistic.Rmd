---
title: "Linear Discriminant Analysis and Logistics Regression"
author: "Sanjaya Mananage"
output:
  pdf_document: default
  html_document: default
  word_document: default
header-includes: 
  - \usepackage{graphicx}
  - \usepackage{float}
geometry: "left=2cm,right=2cm,top=1.5cm,bottom=1.5cm"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(DT)
library(xtable)
```


## (a) linear discriminant function analysis

## Create a new variable “Admission_Status” based on the criteria, if Chance_of_Admit >= 0.7 - Admit(1) and otherwise Do not admit (0). 

```{r}
Admission<-read.csv("Admission_Predict.csv")
Admission<-Admission[,-1]
Admission$Admission_Status<-ifelse(Admission$Chance_of_Admit>=0.7,1,0)
```

## Linear discriminant function analysis to classify future applicant as admit or do not admit on other variables.  

```{r,warning=FALSE,message=FALSE}
attach(Admission)

library(MASS)
dis<-lda(Admission_Status ~ GRE_Score+ TOEFL_Score +University_Rating + SOP + LOR + CGPA + Research,
         data=Admission,prior=c(1/2,1/2))
dis
names(dis)
dis$scaling #coefficients are saved here

```


## Classification rule:

$\hat{a_1}= [0.04859038, 0.01617842, 0.14987272, -0.08706974, 0.18329397, 0.88150770, 0.39318518]$

Group means:
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
$\bar{x}_k$ & GRE\_Score & TOEFL\_Score & University\_Rating & SOP & LOR & CGPA & Research\\
\hline
$0$& 307.0131  &  102.5882   &  2.261438 & 2.741830 & 2.875817 & 8.087974 & 0.2483660 \\
$1$& 322.8745  &  110.3968  & 3.599190 & 3.807692 & 3.809717 & 8.915425 & 0.7327935\\
\hline
\end{tabular}
\end{table}

for $k^{th}$ group compute $\sum^2_{j=1}(\hat{y_j}-\bar{y}_{kj})^2=\sum^2_{j=1}(\hat{\mathbf{a}}_j^\prime\mathbf{x}-\hat{\mathbf{a}}_j^\prime\mathbf{\bar{x}}_k)^2$

where k=0,1

The group that has minimum value of the above sum of squared distance is assigned $x$.

## Suppose a new application comes with GRE Score = 310, TOEFL Score = 110, University Rating = 3, Statement of Purpose = 3, Letter of Recommendation Strength = 3, Undergraduate GPA = 8.5 and Research Experience = 1. 

The admission status for this new applicant. 

```{r,warning=FALSE,message=FALSE}
#Observations on  new bulls that need to be classified
newdata<-data.frame(320,110,3,3,3,8.5,1)
colnames(newdata)<-colnames(Admission[-c(8:9)])
newdata
# prediction of classes for the new observations
predict(dis,newdata=newdata)$class
```


According to the classification rule the new observation $x=(320,110,3,3,3,8.5,1)$ is classified to the group 1 (Admit)


## The plug-in (APER) and leave-one-out (AER) estimates of misclassification rates


```{r}
cat("##APER\n")
pred.group1<-predict(dis,method="plug-in")$class
table(Admission_Status, pred.group1)

APER<-(49+14)/400
APER


cat("\n##AER\n")
dis2<-lda(Admission_Status ~ GRE_Score+ TOEFL_Score +University_Rating + SOP + LOR + CGPA + Research,
          data=Admission,prior=c(1/2,1/2), CV=TRUE)
table(Admission_Status, dis2$class)

AER<-(52+15)/400
AER
```

Plug-in(APER) = $0.1575$

Leave-one-out(AER) = $0.1675$

AER is greater than APER.

## (b) LDA with three class variable 

Now create the second new variable “Admission_Status2” with three classes based on the criteria, if (Chance_of_Admit >= 0.8) - Admit (1) else if (0.8 > Chance_of_Admit >= 0.5) - Borderline (2) and otherwise Do not admit (3). 


```{r}
#Admission<-read.csv("Admission_Predict.csv")
#Admission<-Admission[,-1]
Admission$Admission_Status2<-ifelse(Admission$Chance_of_Admit>=0.8,1, 
                                    ifelse(Admission$Chance_of_Admit>=0.5,2,3))
table(Admission$Admission_Status2)
```




```{r,warning=FALSE,message=FALSE}
attach(Admission)

##b
library(MASS)
dis<-lda(Admission_Status2 ~ GRE_Score+ TOEFL_Score +University_Rating + SOP + LOR + CGPA + Research,
         data=Admission,prior=c(1/3,1/3,1/3))
dis
names(dis)
dis$scaling #coefficients are saved here

#Observations on  new bulls that need to be classified
newdata<-data.frame(320,110,3,3,3,8.5,1)
colnames(newdata)<-colnames(Admission[-c(8:10)])
newdata
# prediction of classes for the new observations
predict(dis,newdata=newdata)$class
```

Two Classification rules:

$\hat{a_1}= [-0.009260823, -0.072394662, -0.014757895, 0.203656079, -0.230082565, -1.907665862, -0.458033441]$

$\hat{a_2}= [0.0044667328, -0.0008867583, 0.9563982049, 0.6048251753, -0.8935530145, -1.5892951724, 0.9968816146]$

Group means:
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
$\bar{x}_k$ & GRE\_Score & TOEFL\_Score & University\_Rating & SOP & LOR & CGPA & Research\\
\hline
$1$& 328.3281 &  113.58594 & 4.148438 & 4.242188 & 4.132812 & 9.241953 & 0.9296875\\
$2$& 312.6736 &  105.19665 & 2.661088 & 3.073222 & 3.228033 & 8.378033 &  0.3933054\\
$3$& 302.0606 & 99.48485 & 2.060606 & 2.500000 & 2.439394 & 7.704545 & 0.1818182\\
\hline
\end{tabular}
\end{table}

for $k^{th}$ group compute $\sum^2_{j=1}(\hat{y_j}-\bar{y}_{kj})^2=\sum^2_{j=1}(\hat{\mathbf{a}}_j^\prime\mathbf{x}-\hat{\mathbf{a}}_j^\prime\mathbf{\bar{x}}_k)^2$

where k=1,2,3

The group that has minimum value of the above sum of squared distance is assigned $x$.

According to the classification rule the above new observation $x=(320,110,3,3,3,8.5,1)$ is classified to the group 2 (Borderline)


## The plug-in (APER) and leave-one-out (AER) estimates of misclassification rates for two LDAs


```{r}
cat("##APER\n")
pred.group1<-predict(dis,method="plug-in")$class
table(Admission_Status2, pred.group1)

APER<-(9+31+39+6)/400
APER


cat("\n##AER\n")
dis2<-lda(Admission_Status2 ~ GRE_Score+ TOEFL_Score +University_Rating + SOP + LOR + CGPA + Research,
          data=Admission,prior=c(1/3,1/3,1/3), CV=TRUE)
table(Admission_Status2, dis2$class)

AER<-(9+32+40+6)/400
AER
```

Plug-in(APER) = $0.2125$

Leave-one-out(AER) = $0.2175$

AER is greater than APER.


## Scatterplot of the first two discriminant scores by labeling different Admission status with different symbols and colors. 

```{r}
dis.ld<-predict(dis)$x
dis.ld<-data.frame(cbind(dis.ld,Admission_Status2=Admission$Admission_Status2))
eqscplot(dis.ld[dis.ld$Admission_Status2==1, 1], dis.ld[dis.ld$Admission_Status2==1, 2],
         xlab = "first linear discriminant", ylab = "second linear discriminant",col=2)
points(dis.ld[dis.ld$Admission_Status2==2, 1], dis.ld[dis.ld$Admission_Status2==2, 2], 
       pch = 2, cex = 0.8, col = 3)
points(dis.ld[dis.ld$Admission_Status2==3, 1], dis.ld[dis.ld$Admission_Status2==3, 2],
       pch = 19, cex = 0.8, col = 4)

legend('topleft',legend=c("Admit", "Borderline", "Do not Admit"),
       pch=c(1,2,19), col=c(2,3,4), bty="n")
```

## (c) Classification rule using logistic regression.  


```{r,warning=FALSE,message=FALSE}
attach(Admission)
fit1 <- glm(Admission_Status ~ GRE_Score+ TOEFL_Score +University_Rating + SOP + LOR + CGPA + Research, 
            family=binomial, data=Admission)
summary(fit1)

newdata<-data.frame(320,110,3,3,3,8.5,1)
colnames(newdata)<-colnames(Admission[-c(8:10)])
newob<- predict(fit1, newdat= newdata,type="response")
newob

cat("##APER") 
#Plug-in estimate
table(Admission_Status,(predict(fit1, type="response")>0.5))
APER<-(25+24)/400
APER

cat("##AER")
#Cross-Validation (Leave-one-out method)
newpred <- numeric(length(Admission_Status))

for (i in 1:length(Admission_Status)){
newdat <- Admission[-i,]
newfit <- glm(Admission_Status ~ GRE_Score+ TOEFL_Score +University_Rating + SOP + LOR + CGPA + Research, 
              family=binomial, data=newdat)
newpred[i] <- predict(newfit, newdat=Admission[i,-c(8:10)],  type="response")

}

table(Admission_Status,(newpred>0.5))

AER<-(30+27)/400
AER
```
If $\hat{p}(x_0)>0.5$ then classify $x_0$ to 1(Admit) otherwise Do not admit.

$\hat{p}(x_0)=0.8534825 >.5$. So we assign new observation to 1(Admit).

Plug-in(APER) = $0.1225$

Leave-one-out(AER) = $0.1425$

AER is greater than APER. 

